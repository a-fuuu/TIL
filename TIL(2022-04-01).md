# 데이터분석



## 가설세우기

- 서울에서 가장 부자동네 **강남 3구 (강남구, 서초구, 송파구)** 에 거주하는 사람들이 스스로가 안전하다고 느낀다고 인터뷰 한 적이 있다.

- 과연 실제로 안전한지 데이터를 통해서 검증해보자.

```python
# 1. 데이터 불러오기

cctv_seoul = ("01. CCTV_in_Seoul.csv")       # 서울 cctv 데이터
pop_seoul  = ("01. population_in_Seoul.xls") # 서울 인구 데이터
```



## 컬럼 정리하기

- `rename` 메소드 사용하기

```python
df_cctv = df_cctv.rename(
    columns={"기관명" : "구별"}
) # df_cctv.columns[0] = "구별" 이런식으로는 수정이 안됐다 튜플 자료형이라서...
df_cctv.head()
```



## 엑셀파일 불러오기 (.xls , .xlxs )

- pandas의 `read_excel` 함수 사용하기



## 데이터를 불러오면서 엑셀의 컬럼, 행을 선택하기

- 되도록 원본 파일 자체를 수정하지는 말것

```python
df_pop = pd.read_excel(
    pop_seoul,
    header = 2,                # 위에서 두 행 제거하고 가져오기)
    usecols = "B, D, G, J, N"  # 엑셀 열! 1열은 A 이런식으로 
)
df_pop.columns = ["구별", "인구수", "한국인", "외국인", "고령자"]
df_pop.head()
```



## 데이터 살펴보기

### CCTV 데이터 살펴보기

`isnull()` 함수를 이용해서 NaN값이 존재하는 곳을 확인한다

```python
df_pop[ df_pop['구별'].isnull() ]
```

`dropna` 메소드를 통해 NaN값이 있는 행 제거

```python
df_pop.dropna(axis = 0,inplace = True) #여기서 axis = 1을 한다면 nan값이 있는 열이 날라가버린다.
df_pop.info()
```



# Numpy를 통한 통계분석

```python
import numpy as np

data1 = np.array([3,4,5,6,7])
data2 = np.array([1,3,5,7,9])

# 평균
np.mean(data1), np.mean(data2)

# 분산확인 Variance
np.var(data1), np.var(data2)

# 표준편차확인 standard deviation
np.std(data1), np.std(data2)
```



# 공분산 ( Covariance )

- 두 집단간의 상관정도를 나타낸다
- **방향성**은 보여줄 수 있으나, 강도를 나타내는데 한계가 있다.
- 음의 상관관계, 양의 상관관계를 보여줄 수 있다 하지만 그 관계의 강도를 나타내는데 어려움이 있다.
  - 표본 데이터의 크기에 따라서 값의 차이가 큰 단점이 있다.
  - 따라서 집다나간의 상관관계만을 확인할 수 있을 뿐 관계의 강도를 확인할 수 없다.

```python
# 공분산 수식 구현하기
def covariance(data1, data2):
  x_ = np.mean(data1)
  y_ = np.mean(data2)
  cov = (data1 - x_) * (data2 - y_)
  cov = np.sum(cov)
  return cov / (len(data1) - 1)

# test code 1
# data1이 커질떄 data2도 같이 커진다 -> data1과 data2가 양의 상관관계를 갖고있다
data1 = np.array([80,85,100,90,95])
data2 = np.array([70,80,100,95,95])

covariance(data1,data2) 
# 수치에 대한 이해보다는 음인지 양인지만 체크하는것이 좋다.

# test code 2
# data3가 커질때 data4는 작아진다.
data3 = np.array([80, 95, 100, 90, 95])
data4 = np.array([100, 90, 70, 90, 80])

covariance(data3, data4)
# 음의 상관관계를 갖고있는것으로 나타난다.

# 상관계수 수식 구현하기
def corrcoef(data1, data2):
  x_ = np.mean(data1)
  y_ = np.mean(data2)

  x_y_var = np.sum((data1 - x_ ) ** 2) * np.sum((data2 - y_) ** 2)
  x_y_cov = np.sum((data1 - x_)*(data2 - y_))

  return x_y_cov / np.sqrt(x_y_var)
```



## 결정계수 (coefficient of determination : R - squared)

- x로부터 y를 예측할 수 있는 정도를 나타낸다

- 어떠한 요건에 의해서(x) 결과(y)가 결정이 되었는지 확인한다
  - 수치적으로 나타낸 것을 **상관계수**라고 한다.
- 상관계수 (r, 피어슨 상관계수)
  - 상관계수 절대값이 0.1 이하면 무시해도 되는 상관관계
  - 상관계수 절대값이 0.1 ~ 0.3이면 약한 상관관계
  - 상관계수 절대값이 0.3 ~ 0.7이면 뚜렷한 상관관계
  - 상관계수 절대값이 0.7 ~ 1이면 강한 상관관계



## Scatter plot에서 선형 회귀선 그리기

- np.polyfit(x, y, dim)
  - x : x축에 들어갈 데티어 y=f(x) 에서 x를 의미
  - y : x축의 기울기와 절편을 구할 기준 데이터
  - dim : 차수 (1이면 1차식 2면 2차식)
- np.polyfit을 통해서 선형회귀선의 기울기와 y절편 값을 구할 수 있다.

```python
fo1 = np.polyfit(data_result["인구수"], data_result["소계"],1)
# array 형태로 기울기와 절편값을 구한다.

# 구해진 기울기와 절편을 이용해서 1차함수를 만든다
f1 = np.poly1d(fo1)					  # poly1d 메소드를 통해 1차 함수 생성
fx = np.linspace(100000, 700000, 100) # 100000부터 700000사이를 100 간격으로 뽑는다.
```
